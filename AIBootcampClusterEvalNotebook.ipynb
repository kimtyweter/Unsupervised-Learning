{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "308980d1",
   "metadata": {},
   "source": [
    "First we will demonstrate how to calculate intrinsic cluster quality metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dbc0f9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import required libraries\n",
    "import os\n",
    "from sklearn.cluster        import KMeans\n",
    "from sklearn                import metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f32ed20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method uses the sklearn metrics library to generate our desired evaluations\n",
    "def evaluate_clustering_performance(X, prediction):\n",
    "    silhouette = metrics.silhouette_score(X, prediction)\n",
    "    chs = metrics.calinski_harabasz_score(X, prediction)\n",
    "    dbs = metrics.davies_bouldin_score(X, prediction)\n",
    "    \n",
    "    return (silhouette, chs, dbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29c5e89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This method takes in an embedding file and loads them in a format to be clustered\n",
    "def load_embedding(filename):\n",
    "    f = open(filename, \"r\")\n",
    "    n, d = [int(x) for x in f.readline().split(\" \")]\n",
    "    embedding = np.zeros((n, d))\n",
    "    for i in range(n):\n",
    "        l = np.asarray([float(x) for x in f.readline().split(\" \")])\n",
    "        for j in range(d):\n",
    "            embedding[int(l[0])][j] = l[j + 1]\n",
    "    f.close()\n",
    "\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f18a86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Loading Graph Embeddings\n",
      "\n",
      "Embeddings Loaded.\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "# First, we take in a file that has generated nodal embeddings\n",
    "print(\"====================\\nLoading Graph Embeddings\\n\")\n",
    "embedding_file = (f\"TADW.nv\")\n",
    "graph_embedding = load_embedding(embedding_file)\n",
    "print(\"Embeddings Loaded.\\n====================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6678a6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KMeans] Clustering Finished.\n"
     ]
    }
   ],
   "source": [
    "# Second, we use K means clustering to generate 9 clusters from our loaded graph embeddings\n",
    "kmeans = KMeans(n_clusters=9).fit(graph_embedding)\n",
    "kmeans_prediction = kmeans.labels_\n",
    "\n",
    "#Third, we evaluate the clustering performance through the intrinsic quality of our clusters\n",
    "kmeans_performance = evaluate_clustering_performance(graph_embedding, kmeans_prediction)\n",
    "print(\"[KMeans] Clustering Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a161740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette: 0.261\tCH: 56.485\tDB: 1.683\t\n"
     ]
    }
   ],
   "source": [
    "#Finally, we print out our stored evaluation metrics\n",
    "k_s, k_c, k_d = kmeans_performance\n",
    "print(\"Silhouette: {:.3f}\\tCH: {:.3f}\\tDB: {:.3f}\\t\".format(k_s, k_c, k_d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f820074",
   "metadata": {},
   "source": [
    "Now we will demonstrate how to evaluate extrinsic metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ad4a443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import additional libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f07e000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this evaluation, you need to read in a csv of your ground truth labels and a csv of the predicted labels\n",
    "# Step 1: Load ground truth data\n",
    "# Import labeled ground truth dataset into pandas dataframe from csv\n",
    "repos_true_labels = pd.read_csv(\"nrel_repos_true_labels.csv\")\n",
    "\n",
    "# Create copies of each dataframe to manipulate\n",
    "repos_true_df = repos_true_labels.copy()\n",
    "\n",
    "# Slice dataframe to get index number from ground truth dataset. Use column names for selection.\n",
    "repos_index = repos_true_df['id']\n",
    "\n",
    "# Slice dataframe to get label from ground truth dataset. Use column names for selection.\n",
    "repo_gold = repos_true_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c0e19ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load predicted data\n",
    "# Read in the predicted cluster labels as dataframes\n",
    "repos_predicted = pd.read_csv(\"nrel_labels.csv\")\n",
    "\n",
    "# Slice dataframe to get index number and cluster labels from predicted data. Use column names for selection.\n",
    "repos_predicted = repos_predicted[['ID', 'VADW_6']]\n",
    "\n",
    "# Match the predicted data on the ground truth data based on ID of the data.\n",
    "repos_predicted = repos_predicted[repos_predicted['ID'].isin(repos_index)]\n",
    "repos_true_labels = repos_true_labels[repos_true_labels['id'].isin(repos_predicted['ID'])]\n",
    "\n",
    "# Create copies of each dataframe to manipulate\n",
    "repos_true_df = repos_true_labels.copy()\n",
    "\n",
    "# Slice dataframe to get index number from ground truth dataset. Use column names for selection.\n",
    "repos_index = repos_true_df['id']\n",
    "\n",
    "# Slice dataframe to get label from ground truth dataset. Use column names for selection.\n",
    "repo_gold = repos_true_df['label']\n",
    "\n",
    "# Add final dataframe to list. If there is more than one dataset, just repeat the code above\n",
    "# for the predicted data and add the dataframes to the appropriate lists below.\n",
    "repos = [repos_predicted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04cdb276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI: 0.012010711577649737\n",
      "AMI: -0.00023805946030836558\n",
      "Completeness: 0.0778597178686849\n",
      "Homogeneity: 0.07467474878292164\n",
      "V-Measure: 0.07623398173257341\n"
     ]
    }
   ],
   "source": [
    "for i in repos:\n",
    "    labels = i['VADW_6']\n",
    "    labels_pred = labels.to_list()\n",
    "    labels_true = repo_gold.to_list()\n",
    "\n",
    "    ari = metrics.adjusted_rand_score(labels_true, labels_pred)\n",
    "    ami = metrics.adjusted_mutual_info_score(labels_true, labels_pred)\n",
    "    comp = metrics.completeness_score(labels_true, labels_pred)\n",
    "    homog = metrics.homogeneity_score(labels_true, labels_pred)\n",
    "    vmeasure = metrics.v_measure_score(labels_true, labels_pred)\n",
    "    print(\"ARI: \" + str(ari))\n",
    "    print(\"AMI: \" + str(ami))\n",
    "    print(\"Completeness: \" + str(comp))\n",
    "    print(\"Homogeneity: \" + str(homog))\n",
    "    print(\"V-Measure: \" + str(vmeasure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac3e88e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
